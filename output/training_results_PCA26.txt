
 Iperparametri ottimali: 
{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}

 Accuracy: 
0.8478333333333333

 Best score: 
0.8277083333333334

Classification Report:
              precision    recall  f1-score   support

           1       0.86      0.85      0.86        95
           2       0.71      0.90      0.79        81
           3       0.84      0.98      0.90       101
           4       0.88      0.95      0.92        85
           5       0.81      0.94      0.87        98
           6       0.91      0.93      0.92       107
           7       0.88      0.92      0.90       103
           8       0.86      0.98      0.92       100
           9       0.97      0.99      0.98       110
          10       0.90      0.97      0.94        98
          11       0.88      0.95      0.92       103
          12       0.97      0.95      0.96        98
          13       0.86      0.80      0.83       100
          14       0.78      0.81      0.80        94
          15       0.88      0.89      0.89        92
          16       0.92      0.89      0.90       112
          17       0.81      0.75      0.78       112
          18       0.73      0.80      0.76        99
          19       0.93      0.84      0.88       105
          20       0.89      0.76      0.82       109
          21       0.92      0.82      0.86       109
          22       0.76      0.92      0.83        97
          23       0.73      0.75      0.74       106
          24       0.84      0.85      0.85       109
          25       0.86      0.87      0.86        98
          26       0.88      0.92      0.90       118
          27       0.80      0.83      0.81        99
          28       0.96      1.00      0.98        93
          29       0.76      0.68      0.71       109
          30       0.96      0.94      0.95       108
          31       0.89      0.76      0.82       104
          32       0.77      0.82      0.80       100
          33       0.76      0.71      0.73        95
          34       0.89      0.93      0.91        95
          35       0.76      0.59      0.67        93
          36       0.86      0.81      0.83       104
          37       0.85      0.91      0.88        87
          38       0.86      0.77      0.81        98
          39       0.84      0.76      0.80        90
          40       0.82      0.90      0.86        84
          41       0.93      0.83      0.88       120
          42       0.84      0.81      0.83        97
          43       0.77      0.77      0.77       106
          44       0.69      0.81      0.74        84
          45       0.77      0.78      0.77       101
          46       0.80      0.83      0.82       107
          47       0.79      0.76      0.77        97
          48       0.89      0.88      0.88       100
          49       0.81      0.81      0.81       107
          50       0.84      0.80      0.82       114
          51       0.92      0.80      0.86       105
          52       0.93      0.90      0.92       102
          53       0.84      0.73      0.78        84
          54       0.82      0.93      0.87       106
          55       0.86      0.63      0.73       103
          56       0.73      0.77      0.75        88
          57       0.88      0.85      0.86        99
          58       0.88      0.91      0.89        86
          59       0.92      0.93      0.93        91
          60       0.94      0.94      0.94       105

    accuracy                           0.85      6000
   macro avg       0.85      0.85      0.85      6000
weighted avg       0.85      0.85      0.85      6000


Confusion Matrix:
[[81  0  1 ...  0  0  0]
 [ 0 73  0 ...  0  0  0]
 [ 0  0 99 ...  0  0  0]
 ...
 [ 0  0  0 ... 78  0  1]
 [ 0  0  0 ...  1 85  0]
 [ 0  0  0 ...  0  0 99]]

Precision:
0.8497614850932407
Recall:
0.8478333333333333
F1-Score:
0.8468151392927313
