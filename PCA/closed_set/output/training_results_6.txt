
 Iperparametri ottimali: 
{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}

 Accuracy: 
0.8445

 Best score: 
0.828784277974578

Classification Report:
              precision    recall  f1-score   support

           1       0.89      0.93      0.91        94
           2       0.78      0.89      0.83        82
           3       0.83      0.90      0.86       101
           4       0.82      1.00      0.90        85
           5       0.77      0.92      0.84        98
           6       0.89      0.86      0.88       107
           7       0.86      0.93      0.89       103
           8       0.83      0.95      0.88       100
           9       0.96      0.98      0.97       110
          10       0.85      0.97      0.90        98
          11       0.89      0.96      0.93       103
          12       0.98      0.96      0.97        98
          13       0.86      0.87      0.87       100
          14       0.76      0.88      0.82        94
          15       0.86      0.89      0.88        91
          16       0.90      0.93      0.91       113
          17       0.83      0.76      0.79       112
          18       0.82      0.77      0.79        98
          19       0.88      0.79      0.84       106
          20       0.87      0.57      0.69       108
          21       0.89      0.78      0.83       110
          22       0.78      0.87      0.82        97
          23       0.74      0.71      0.72       106
          24       0.87      0.83      0.85       109
          25       0.90      0.84      0.87        98
          26       0.89      0.92      0.90       118
          27       0.79      0.71      0.74        99
          28       1.00      0.99      0.99        92
          29       0.79      0.68      0.73       109
          30       0.87      0.94      0.90       108
          31       0.86      0.80      0.83       104
          32       0.73      0.84      0.78       100
          33       0.83      0.75      0.79        96
          34       0.88      0.97      0.92        95
          35       0.77      0.59      0.67        92
          36       0.87      0.78      0.82       105
          37       0.84      0.87      0.86        87
          38       0.84      0.81      0.82        98
          39       0.71      0.74      0.72        90
          40       0.87      0.92      0.89        84
          41       0.90      0.86      0.88       120
          42       0.86      0.76      0.81        97
          43       0.89      0.69      0.78       106
          44       0.70      0.89      0.79        84
          45       0.80      0.80      0.80       101
          46       0.84      0.77      0.80       107
          47       0.83      0.87      0.85        97
          48       0.92      0.91      0.91        99
          49       0.82      0.79      0.80       108
          50       0.79      0.83      0.81       114
          51       0.88      0.87      0.88       105
          52       0.91      0.92      0.92       102
          53       0.78      0.69      0.73        84
          54       0.81      0.90      0.85       105
          55       0.89      0.77      0.82       104
          56       0.69      0.82      0.75        88
          57       0.75      0.78      0.77        99
          58       0.92      0.92      0.92        86
          59       0.92      0.96      0.94        89
          60       0.96      0.93      0.95       107

    accuracy                           0.84      6000
   macro avg       0.85      0.85      0.84      6000
weighted avg       0.85      0.84      0.84      6000


Confusion Matrix:
[[ 87   1   0 ...   0   0   0]
 [  0  73   0 ...   0   0   0]
 [  0   0  91 ...   0   0   0]
 ...
 [  0   0   0 ...  79   0   0]
 [  0   0   0 ...   0  85   0]
 [  0   0   0 ...   1   0 100]]

Precision:
0.8467041940884045
Recall:
0.8445
F1-Score:
0.8429530136383558
